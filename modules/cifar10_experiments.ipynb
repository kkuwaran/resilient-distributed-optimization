{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from topology_generation import Topology\n",
    "from adversaries import Adversaries\n",
    "from objective_functions_cifar10 import DecentralizedCIFAR10\n",
    "from resilient_algorithms import ResilientAlgorithms\n",
    "from algorithmic_framework import DistributedAlgorithmFramework_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for CIFAR-10 experiments\n",
    "seed = 42   \n",
    "alg_name = 'CWTM'  # chosen from ['DGD', 'CWTM', 'SDFD', 'R-SDMMFD']\n",
    "n_adv = 1   \n",
    "\n",
    "# fundamental parameters\n",
    "n_nodes = 10\n",
    "n_epochs = 3\n",
    "\n",
    "# function parameters\n",
    "batch_size = 64\n",
    "bias_flag = False\n",
    "\n",
    "# topology parameters\n",
    "topo_type = 'r-robust'\n",
    "period = 1\n",
    "hyperparams_dict = {'threshold': 0.20, 'robustness': 4}\n",
    "F = 1\n",
    "\n",
    "# adversary model parameters\n",
    "attack_info = {'type': 'perturbation', 'param': 0.01, \n",
    "               'perturbation_mode': 'gaussian', 'broadcast_flag': False}\n",
    "adv_model = 'local'\n",
    "\n",
    "# baseline parameters\n",
    "baseline_epochs = 30\n",
    "baseline_optimizer = 'SGD'\n",
    "baseline_opt_config = {'learning_rate': 0.002, 'momentum': 0.9}\n",
    "\n",
    "# framework parameters\n",
    "state_inits = {'main': None, 'aux': None}\n",
    "stepsize_init = {'type': 'constant', 'param': 0.04}\n",
    "directory = f'../results/exp_cifar10_adv{n_adv}/'\n",
    "eval_info = {'n_nodes': None, 'period': 5, 'n_eval_iters': 100, 'path_name': directory}\n",
    "\n",
    "# miscellaneous parameters\n",
    "self_flag = True\n",
    "acceleration_flag = True\n",
    "verify_flag = False\n",
    "display_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create directory\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "### set random seed\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.experimental.numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "### initialize objects\n",
    "topology = Topology(topo_type, n_nodes, period, **hyperparams_dict)\n",
    "adversaries = Adversaries(topology.adjacencies[0], n_adv, adv_model, attack_info, display_flag)\n",
    "function = DecentralizedCIFAR10(n_nodes, batch_size, bias_flag, adversaries.reg_indices, display_flag)\n",
    "framework = DistributedAlgorithmFramework_ML(topology, function, adversaries, eval_info)\n",
    "algorithm = ResilientAlgorithms(alg_name, F, self_flag, acceleration_flag, verify_flag, display_flag)\n",
    "\n",
    "### set-up initialization and execute algorithm\n",
    "start_time_main = time.time()\n",
    "framework.initialization(n_epochs, state_inits, stepsize_init)\n",
    "framework.distributed_algorithm(algorithm)\n",
    "print(f\"Time taken: {time.time() - start_time_main:.2f}s\")\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(f\"Test Accuracy: {np.array(framework.metric_dict['test_acc_avg'])}\")\n",
    "print(f\"Adversary Indices: {framework.adv_indices}\")\n",
    "print(f\"Number of Edges: {int(np.sum(topology.adjacencies[0] / 2))}\")\n",
    "\n",
    "### train baseline\n",
    "if alg_name == 'DGD':\n",
    "    start_time_baseline = time.time()\n",
    "    baseline_dict = function.train_baseline(baseline_epochs, baseline_optimizer, baseline_opt_config, directory)\n",
    "    print(f\"Baseline: Time {time.time() - start_time_baseline:.2f}s; Test Accuracy {baseline_dict['test_acc'][-1]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10 Temporary Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = framework.eval_timesteps\n",
    "names = ['_acc', '_loss']\n",
    "ylabels = ['Accuracy', 'Loss']\n",
    "for name, ylabel in zip(names, ylabels):\n",
    "    # plot average accuracies\n",
    "    plt.plot(x, framework.metric_dict['train' + name + '_avg'], label='train', color='C0')\n",
    "    plt.plot(x, framework.metric_dict['test' + name + '_avg'], label='test', color='C1')\n",
    "    # plot worst accuracies\n",
    "    plt.plot(x, framework.metric_dict['train' + name + '_w'], label='train (worst)', linestyle='dashed', color='C0')\n",
    "    plt.plot(x, framework.metric_dict['test' + name + '_w'], label='test (worst)', linestyle='dashed', color='C1')\n",
    "    plt.title(f\"{alg_name} Algorithm; {attack_info['perturbation_mode']} {attack_info['param']}\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10 Plot (attack strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import Plottings2\n",
    "\n",
    "\n",
    "### set-up plotting parameters\n",
    "# fundamental parameters\n",
    "directory = '../results/!exp_cifar10/adv6_gaussian0050/'\n",
    "attack_param = 0.050\n",
    "n_plot_steps = None\n",
    "y_upper_lim_acc = 85\n",
    "\n",
    "\n",
    "# base plotting parameters\n",
    "title_extension = r' ($\\hat{\\sigma}$ = ' + f'{attack_param})'\n",
    "label_exts = ['', ' (worst)']\n",
    "base_plt = {'ylog': False, 'label_exts': label_exts, 'title_ext': title_extension}\n",
    "\n",
    "# metric groups\n",
    "train_acc_group = ['train_acc_avg', 'train_acc_w']\n",
    "bl_train_acc = 'train_acc_baseline'\n",
    "train_acc_plt = {'nickname': 'train_accuracy', 'ylabel': 'Train Accuracy', \n",
    "                 'limit': [0, n_plot_steps, 0, y_upper_lim_acc], 'acc_flag': True}\n",
    "\n",
    "test_acc_group = ['test_acc_avg', 'test_acc_w']\n",
    "bl_test_acc = 'test_acc_baseline'\n",
    "test_acc_plt = {'nickname': 'test_accuracy', 'ylabel': 'Test Accuracy',\n",
    "                'limit': [0, n_plot_steps, 0, y_upper_lim_acc], 'acc_flag': True}\n",
    "\n",
    "train_loss_group = ['train_loss_avg', 'train_loss_w']\n",
    "bl_train_loss = 'train_loss_baseline'\n",
    "train_loss_plt = {'nickname': 'train_loss', 'ylabel': 'Train Loss',\n",
    "                    'limit': [0, n_plot_steps, None, None], 'acc_flag': False}\n",
    "\n",
    "test_loss_group = ['test_loss_avg', 'test_loss_w']\n",
    "bl_test_loss = 'test_loss_baseline'\n",
    "test_loss_plt = {'nickname': 'test_loss', 'ylabel': 'Test Loss',\n",
    "                    'limit': [0, n_plot_steps, None, None], 'acc_flag': False}\n",
    "\n",
    "\n",
    "### create a list of dictionaries for each metric group\n",
    "# create a list of dictionaries for each metric group\n",
    "metric_groups = [{'metrics': train_acc_group, 'baseline': bl_train_acc, 'plt': train_acc_plt}, \n",
    "                 {'metrics': test_acc_group, 'baseline': bl_test_acc, 'plt': test_acc_plt},\n",
    "                 {'metrics': train_loss_group, 'baseline': bl_train_loss, 'plt': train_loss_plt},\n",
    "                 {'metrics': test_loss_group, 'baseline': bl_test_loss, 'plt': test_loss_plt}]\n",
    "\n",
    "# include base_plt in each plt_dict\n",
    "for group_dict in metric_groups:\n",
    "    group_dict['plt'].update(base_plt)\n",
    "\n",
    "\n",
    "### create Plottings object and plot results\n",
    "plotting = Plottings2(directory)\n",
    "plotting.plot_results(metric_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10 Plot (adversarial agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import Plottings2\n",
    "\n",
    "\n",
    "### set-up plotting parameters\n",
    "# fundamental parameters\n",
    "directory = '../results/!exp_cifar10/adv24_gaussian0035/'\n",
    "n_adv = 24\n",
    "n_plot_steps = None\n",
    "y_upper_lim_acc = 85\n",
    "\n",
    "\n",
    "# base plotting parameters\n",
    "title_extension = r' ($| \\mathcal{V}_{\\mathcal{B}} |$ = ' + f'{n_adv})'\n",
    "label_exts = ['', ' (worst)']\n",
    "base_plt = {'ylog': False, 'label_exts': label_exts, 'title_ext': title_extension}\n",
    "\n",
    "# metric groups\n",
    "train_acc_group = ['train_acc_avg', 'train_acc_w']\n",
    "bl_train_acc = 'train_acc_baseline'\n",
    "train_acc_plt = {'nickname': 'train_accuracy', 'ylabel': 'Train Accuracy', \n",
    "                 'limit': [0, n_plot_steps, 0, y_upper_lim_acc], 'acc_flag': True}\n",
    "\n",
    "test_acc_group = ['test_acc_avg', 'test_acc_w']\n",
    "bl_test_acc = 'test_acc_baseline'\n",
    "test_acc_plt = {'nickname': 'test_accuracy', 'ylabel': 'Test Accuracy',\n",
    "                'limit': [0, n_plot_steps, 0, y_upper_lim_acc], 'acc_flag': True}\n",
    "\n",
    "train_loss_group = ['train_loss_avg', 'train_loss_w']\n",
    "bl_train_loss = 'train_loss_baseline'\n",
    "train_loss_plt = {'nickname': 'train_loss', 'ylabel': 'Train Loss',\n",
    "                    'limit': [0, n_plot_steps, None, None], 'acc_flag': False}\n",
    "\n",
    "test_loss_group = ['test_loss_avg', 'test_loss_w']\n",
    "bl_test_loss = 'test_loss_baseline'\n",
    "test_loss_plt = {'nickname': 'test_loss', 'ylabel': 'Test Loss',\n",
    "                    'limit': [0, n_plot_steps, None, None], 'acc_flag': False}\n",
    "\n",
    "\n",
    "### create a list of dictionaries for each metric group\n",
    "# create a list of dictionaries for each metric group\n",
    "metric_groups = [{'metrics': train_acc_group, 'baseline': bl_train_acc, 'plt': train_acc_plt}, \n",
    "                 {'metrics': test_acc_group, 'baseline': bl_test_acc, 'plt': test_acc_plt},\n",
    "                 {'metrics': train_loss_group, 'baseline': bl_train_loss, 'plt': train_loss_plt},\n",
    "                 {'metrics': test_loss_group, 'baseline': bl_test_loss, 'plt': test_loss_plt}]\n",
    "\n",
    "# include base_plt in each plt_dict\n",
    "for group_dict in metric_groups:\n",
    "    group_dict['plt'].update(base_plt)\n",
    "\n",
    "\n",
    "### create Plottings object and plot results\n",
    "plotting = Plottings2(directory)\n",
    "plotting.plot_results(metric_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
